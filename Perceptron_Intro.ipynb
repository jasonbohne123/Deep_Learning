{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d6db897-f647-4da1-91a0-b561e2854bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-21 07:47:44.114381: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-21 07:47:44.114495: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# ^^^ pyforest auto-imports - don't write above this line\n",
    "# to remove errors \n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39526916-d6f8-42cc-8c8a-a92f34b76a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996fab4d-3772-4db5-a5ec-63d6473618bd",
   "metadata": {},
   "source": [
    "Perceptrons - Core of ANN\n",
    "   - A layer of Linear Threshold Units that are a type of artifical neuron\n",
    "   - Given an input vector of features we train for optimal weights on each neuron s.t. our loss function is minimized\n",
    "   - The underlying optimization problem is solved via Stochastic Gradient Descent\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75153fe2-f71f-4faa-933c-e6990e8c0766",
   "metadata": {},
   "source": [
    "Using Iris dataset note the Attribute Information:\n",
    "   1. sepal length in cm\n",
    "   2. sepal width in cm\n",
    "   3. petal length in cm\n",
    "   4. petal width in cm\n",
    "   5. class: Iris Setosa/Iris Versicolour/Iris Virginica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edc0736a-7260-42f5-848a-4e4af66b232f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width          target\n",
       "0             5.1          3.5           1.4          0.2     Iris-setosa\n",
       "1             4.9          3.0           1.4          0.2     Iris-setosa\n",
       "2             4.7          3.2           1.3          0.2     Iris-setosa\n",
       "3             4.6          3.1           1.5          0.2     Iris-setosa\n",
       "4             5.0          3.6           1.4          0.2     Iris-setosa\n",
       "..            ...          ...           ...          ...             ...\n",
       "145           6.7          3.0           5.2          2.3  Iris-virginica\n",
       "146           6.3          2.5           5.0          1.9  Iris-virginica\n",
       "147           6.5          3.0           5.2          2.0  Iris-virginica\n",
       "148           6.2          3.4           5.4          2.3  Iris-virginica\n",
       "149           5.9          3.0           5.1          1.8  Iris-virginica\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris=pd.read_csv('/home/jbohn/jupyter/datasets/ML_Data/Iris/iris.csv',names=['sepal_length','sepal_width','petal_length','petal_width','target'])\n",
    "features=['sepal_length','sepal_width','petal_length','petal_width']\n",
    "iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52521e96-12cc-4dd8-8458-3163dbc00b99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>6.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>6.2</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>6.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width\n",
       "92            5.8          2.6           4.0          1.2\n",
       "137           6.4          3.1           5.5          1.8\n",
       "54            6.5          2.8           4.6          1.5\n",
       "97            6.2          2.9           4.3          1.3\n",
       "140           6.7          3.1           5.6          2.4\n",
       "..            ...          ...           ...          ...\n",
       "108           6.7          2.5           5.8          1.8\n",
       "63            6.1          2.9           4.7          1.4\n",
       "60            5.0          2.0           3.5          1.0\n",
       "52            6.9          3.1           4.9          1.5\n",
       "26            5.0          3.4           1.6          0.4\n",
       "\n",
       "[112 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,X_test,Y_train,Y_test=train_test_split(iris[features],iris['target'],train_size=0.75)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b90c47-70cd-4442-b6f7-3b8f9329abd7",
   "metadata": {},
   "source": [
    "Now we are ready to fit a perceptron model on the training data. To find the parameterized perceptron model with the minimized loss we apply stochastic gradient descent.\n",
    "\n",
    "This assumes our target function is differentiable and convex\n",
    "\n",
    "Moreover our target function will separate our target space into m-subspaces with m-1 hyperplanes. By perceptron convergence thrm this will only converge if the data is linearly separable \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "980218cc-6e78-45dc-8e90-96149aedb5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha 0.0001\n",
      "class_weight None\n",
      "early_stopping False\n",
      "eta0 1.0\n",
      "fit_intercept True\n",
      "l1_ratio 0.15\n",
      "max_iter 1000\n",
      "n_iter_no_change 5\n",
      "n_jobs None\n",
      "penalty None\n",
      "random_state 0\n",
      "shuffle True\n",
      "tol 0.001\n",
      "validation_fraction 0.1\n",
      "verbose 0\n",
      "warm_start False\n"
     ]
    }
   ],
   "source": [
    "clf = Perceptron(tol=1e-3)\n",
    "clf.fit(X_train.values, Y_train.values)\n",
    "param_dict=clf.get_params()\n",
    "param_dict\n",
    "for key,value in param_dict.items():\n",
    "    print(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "385838a8-c4a7-491b-a09a-ef37ee763db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test Data is 0.9736842105263158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jbohn/miniconda3/envs/research/lib/python3.7/site-packages/sklearn/base.py:444: UserWarning: X has feature names, but Perceptron was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    }
   ],
   "source": [
    "score=clf.score(X_test, Y_test)\n",
    "print(\"Accuracy on Test Data is\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d46dbe1-ed79-40a3-8796-85b0770382dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jbohn/miniconda3/envs/research/lib/python3.7/site-packages/sklearn/base.py:444: UserWarning: X has feature names, but Perceptron was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[13,  0,  0],\n",
       "       [ 0, 10,  1],\n",
       "       [ 0,  0, 14]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred=clf.predict(X_test)\n",
    "confusion_matrix(Y_test,Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74dcad2d-738a-49b0-bb94-a9eda23d251d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        13\n",
      "Iris-versicolor       1.00      0.91      0.95        11\n",
      " Iris-virginica       0.93      1.00      0.97        14\n",
      "\n",
      "       accuracy                           0.97        38\n",
      "      macro avg       0.98      0.97      0.97        38\n",
      "   weighted avg       0.98      0.97      0.97        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test,Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc7c4fd-f0b6-4628-938e-e8836e20f84f",
   "metadata": {},
   "source": [
    "Multi-Layer Perceptrons \n",
    "   - Multiple layers of Perceptrons with either the same/different activation functions\n",
    "   - We can think of this as finding the most likely transformation function (projection) of our feature space into our target space. \n",
    "   - I.e. our feature might not share the same space as our target but a nonlinear function of our feature might\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04679562-d78f-434a-8354-6a77c20d57d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0e8214-b16c-49da-943e-8e5e8148d34a",
   "metadata": {},
   "source": [
    "Standardizing data to a normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "81a76bc7-c207-44a6-aab0-65e58c26a240",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler=scaler.fit(X_train)\n",
    "scaled_X_train=scaler.transform(X_train)\n",
    "scaled_X_test=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5803759-8678-4c0b-89ad-cf9f04f74044",
   "metadata": {},
   "source": [
    "Let's fit a MLP of 1 hidden layer where activation function is RELU and we numerically solve for the weight values using LBFGS Optimiazaiton and a L2 Regularization of $\\alpha$. \n",
    "\n",
    "The loss function here is Log-Loss (Penalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "a83d7440-575c-4489-9e1a-7b4d025ba371",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier(solver='lbfgs', alpha=0.0001,hidden_layer_sizes=(1))\n",
    "model=clf.fit(scaled_X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "3ab6ab77-f457-45a6-a66c-4c2983798341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'relu',\n",
       " 'alpha': 0.0001,\n",
       " 'batch_size': 'auto',\n",
       " 'beta_1': 0.9,\n",
       " 'beta_2': 0.999,\n",
       " 'early_stopping': False,\n",
       " 'epsilon': 1e-08,\n",
       " 'hidden_layer_sizes': 1,\n",
       " 'learning_rate': 'constant',\n",
       " 'learning_rate_init': 0.001,\n",
       " 'max_fun': 15000,\n",
       " 'max_iter': 200,\n",
       " 'momentum': 0.9,\n",
       " 'n_iter_no_change': 10,\n",
       " 'nesterovs_momentum': True,\n",
       " 'power_t': 0.5,\n",
       " 'random_state': None,\n",
       " 'shuffle': True,\n",
       " 'solver': 'lbfgs',\n",
       " 'tol': 0.0001,\n",
       " 'validation_fraction': 0.1,\n",
       " 'verbose': False,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_params()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "bc2e99a4-9cb5-4895-8840-68c83f91c978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Achieved Loss in 111 iterations\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Achieved Loss in\",model.n_iter_, \"iterations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "ff318133-bb26-4f3d-8829-4e192999f154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(scaled_X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "3048d373-4c05-4f0c-8870-2488f07f4b6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13,  0,  0],\n",
       "       [ 0, 11,  0],\n",
       "       [ 0,  0, 14]])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred=clf.predict(scaled_X_test)\n",
    "confusion_matrix(Y_test,Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911ed678-530a-4efa-b25f-720c59a320b7",
   "metadata": {},
   "source": [
    "Now fitted with logstic activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "2a04459f-40fa-4061-8a75-045fe61fa121",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier(solver='lbfgs',activation='logistic', alpha=0.0001,hidden_layer_sizes=(1))\n",
    "model=clf.fit(scaled_X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "b4504ded-57a3-4a28-a127-1ff47e53b1c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Achieved Loss in 60 iterations\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Achieved Loss in\",model.n_iter_, \"iterations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "bf1b4de7-417c-4e6b-b7e8-869ce086e9fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(scaled_X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "ac385818-cc2f-4309-9390-6a7986ca4de0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13,  0,  0],\n",
       "       [ 0, 11,  0],\n",
       "       [ 0,  0, 14]])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred=clf.predict(scaled_X_test)\n",
    "confusion_matrix(Y_test,Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb16d5cd-8b1f-4bde-b3e8-492ba3accf5d",
   "metadata": {},
   "source": [
    "Now let's include a different optimization function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "bcd3638c-aec6-4047-b5c5-7db01f3a9597",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier(solver='adam',activation='logistic', alpha=0.001,hidden_layer_sizes=(1),max_iter=10000)\n",
    "model=clf.fit(scaled_X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "545dfdd0-4c77-4879-a04c-431bb002f04d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Achieved Loss in 1996 iterations\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Achieved Loss in\",model.n_iter_, \"iterations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "e21a89df-af20-45dd-b4da-7878bc107bae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.631578947368421"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(scaled_X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "aa56330d-47aa-4410-94a9-a23386efaf78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13,  0,  0],\n",
       "       [ 0, 11,  0],\n",
       "       [ 0, 14,  0]])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred=clf.predict(scaled_X_test)\n",
    "confusion_matrix(Y_test,Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dad63c3-eb6e-4341-9a92-cd10398e5e25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:research]",
   "language": "python",
   "name": "conda-env-research-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
